{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aee20b09-149e-4cc8-aab9-338ae21a2d4d",
   "metadata": {},
   "source": [
    "# Piecewise Polytropic Example\n",
    "\n",
    "To run this tutorial, you should install NEoST following the install guide. Some extra data files are also required, these are the `examples/J0740.npy` and `examples/GW170817.npy` files and are included in the GitHub repository along with this notebook.\n",
    "\n",
    "Before continuing with this tutorial, please read the inference process overview to familiarise yourself with the way NEoST parametrises the equation of state.\n",
    "\n",
    "The following block of code will properly import NEoST and its prerequisites, furthermore it also defines a name for the inference run, this name is what will be prefixed to all of NEoST's output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e46672c-5e00-44a2-b041-902ccfb3b0cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-776e86549c43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mneost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkalepy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mneost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meos\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpolytropes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtabulated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mneost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPrior\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPrior\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mneost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStar\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'neost'"
     ]
    }
   ],
   "source": [
    "import neost\n",
    "import kalepy\n",
    "from neost.eos import polytropes, tabulated\n",
    "from neost.Prior import Prior\n",
    "from neost.Star import Star\n",
    "from neost.Likelihood import Likelihood\n",
    "from neost import PosteriorAnalysis\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import gaussian_kde\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "from pymultinest.solve import solve\n",
    "import time\n",
    "import os\n",
    "\n",
    "import neost.global_imports as global_imports\n",
    "\n",
    "# Some physical constants\n",
    "c = global_imports._c\n",
    "G = global_imports._G\n",
    "Msun = global_imports._M_s\n",
    "pi = global_imports._pi\n",
    "rho_ns = global_imports._rhons\n",
    "\n",
    "# Define name for run, extra - at the end is for nicer formatting of output\n",
    "run_name = \"PP-example-run-\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c0ad45-1f41-4ba5-87f3-9cbc3eb54623",
   "metadata": {},
   "source": [
    "## Equation of state object\n",
    "With NEoST properly imported the equation of state needs to be defined. For the PP parametrisation this is done by creating a `polytropes.PolytropicEoS()` object. This object takes as input the `crust` parameter, the `rho_t` parameter. \n",
    "\n",
    "Valid input for the crust parameter consists of one of the following values: `'ceft-Hebeler'`, `'ceft-Tews'`, `'ceft-Lynn'`, `'ceft-Drischler'`, `'ceft-old'` or `None`. This instructs NEoST on which cEFT model to use, in order of listing these would be: the band based on the work by Hebeler et al., Tews et al., Lynn et al., Drischler et al., an old implementation of the Hebeler band from Raaijmakers et al., or no cEFT at all.\n",
    "\n",
    "The `rho_t` parameter tells NEoST at which density to transition between the cEFT crust parametrisation and the core parametrisation. This value must not exceed a value of twice the nuclear saturation density, although for the currently implemented cEFT models it should not exceed 1.1 times the nuclear saturation density.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5693baaf-59b3-411e-a481-610d6775d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're exploring a polytropic (PP) EoS parametrization with a chiral effective field theory (cEFT) parametrization based on Hebeler's work\n",
    "# Transition between PP parametrisation and cEFT parametrization occurs at 1.1*saturation density\n",
    "polytropes_pp = polytropes.PolytropicEoS(crust = 'ceft-Hebeler', rho_t = 1.1*rho_ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb61620d-3732-4174-ade4-68e2f22a5f19",
   "metadata": {},
   "source": [
    "This block of code defines the measurements used to create the likelihood function for the Bayesian analysis. It shows you how to define measurements for both SciPy and KalePy, as well as what parameters need to be past for a mass-radius measurement and for a gravitational wave event when using non-synthetic data.\n",
    "\n",
    "To define a mass-radius measurement you need to create a KDE object. For both KalePy and SciPy, you need to provide the samples from which to create the KDE. These samples need to be provided as an array of shape `(2,n)` where `n` is the number of samples of your dataset. The first row should consist of the masses and the second row should consist of the radii. As shown in the example, to turn a dataset into a SciPy KDE consists of simply calling the `gaussian_kde()` function and providing the dataset as argument.\n",
    "\n",
    "To define a gravitational wave event you again have to create a KDE, again the format of the dataset is the same for both a KalePy and a SciPy KDE, but this time the array needs to have a shape of `(4,n)` where `n` again is the number of samples in your dataset. Here the rows correspond to the following quantities respectively:\n",
    "- The chirp mass $M_c$\n",
    "- The mass ratio $Q$\n",
    "- The tidal deformability of the primary $\\Lambda_1$\n",
    "- The tidal deformability of the secondary $\\Lambda_2$\n",
    "\n",
    "For the purposes of this example script we now turn this dataset into a KalePy KDE. We do this by creating a `kalepy.KDE()` object which takes as first argument your dataset, as second argument you provide the reflection bounds of your KDE for each row in your dataset, where `None` indicates no reflection. The `weights` argument provides the weights of your dataset, if your dataset is equally-weighted you do not need to provide this argument. The `bandwidth` parameter allows you to tweak the width of the kernels in your KDE and the `kernel` argument allows you to specify which kernel you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555a5325-d5c2-40b6-af8b-6aa1319ef7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the likelihoods for the individual measurements\n",
    "# First we load the mass-radius measurement\n",
    "mass_radius_j0740 = np.load('j0740.npy').T\n",
    "print(mass_radius_j0740[0])\n",
    "J0740_LL = gaussian_kde(mass_radius_j0740)\n",
    "# And next up is the gravitational wave event\n",
    "GW170817 = np.load('GW170817.npy')\n",
    "print(GW170817.shape)\n",
    "GW170817_LL = kalepy.KDE(GW170817[:,0:4].T, reflect=[[None, None], [None, 1.], [0., None], [0., None]], weights=GW170817[:,4], bandwidth=0.1, kernel='gaussian')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22de3397-b345-4a87-b956-1dafdc9c59e5",
   "metadata": {},
   "source": [
    "Next, these KDEs need to be passed to NEoST, this is done through the `likelihood_functions` and `likelihood_params` lists. The first one is a list of all the (callable) KDEs, and the second one is a list of as many instances of `['Mass', 'Radius']` as you have mass-radius measurements. The ordering of this list matters insofar as that you need to put any mass-radius measurements first in the `likelihood_functions` list and any gravitational wave events second.\n",
    "\n",
    "You will also need to define a `chirp_mass` list containing the median values of the chirp masses of your events, in case your event is a mass-radius measurement, enter `None` instead.\n",
    "\n",
    "Finally you will also need to define how many events you pass to NEoST, a quick and easy way to do this is shown in the example code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cafb803-50bd-4604-a936-f657fe0ba813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the likelihoods to the solver\n",
    "likelihood_functions = [J0740_LL, lambda points: GW170817_LL.density(np.array([points]).T, probability=True)[1][0]]\n",
    "likelihood_params = [['Mass', 'Radius']]\n",
    "\n",
    "# Define whether event is GW or not and define number of stars/events\n",
    "chirp_mass = [None, 1.186]\n",
    "number_stars = len(chirp_mass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e4731c-6d88-49e8-83f9-6cec8ed8e276",
   "metadata": {},
   "source": [
    "If instead you are using synthetic data, for example a 2-dimensional Gaussian distribution, you can define a function that calculates the likelihood directly and pass this on to NEoST as follows:\n",
    "```python\n",
    "# 2-dimensional approximation of the J0740 measurement\n",
    "mu_M = 2.08\n",
    "mu_R = 11.155\n",
    "sigma_M = 0.07 \n",
    "sigma_R = 0.1 # uncertainty in radius\n",
    "J0740 = sps.multivariate_normal(mean=[muM, muR], cov=[[sigM, 0.0], [0.0, sigR]])\n",
    "\n",
    "likelihood_functions = [J0740.pdf]\n",
    "likelihood_params = [['Mass', 'Radius']]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a47adcc-83b0-4936-bb83-a06945a3b69e",
   "metadata": {},
   "source": [
    "With our data defined, the next step is to define both the prior and the likelihood function.\n",
    "\n",
    "The prior is defined through a pair of dictionaries, `variable_params` and `static_params`. Here `variable_params` takes in the equation of state parameters that will be allowed to vary, and `static_params` will take in those that won't. Entries into `variable_params` should be formatted as follows: `'param_name':[lower_bound,upper_bound]`\n",
    "\n",
    "Additionally, for each of the measurements you must also append a dictionary item `'rhoc_i':[14.6, 16]` to the end of `variable_params`, this parameter covers the central density of star i and needs to be appended for each star individually. Entries into `static_params` should be formatted in the following manner: `'param_name':value`.\n",
    "\n",
    "Finally, the prior object must be created using the following function call:`neost.Prior.Prior(EOS, variable_params, static_params, chirp_masses)` where the `EOS` argument is the equation of state object that was created in the previous step. When this prior is called it will then uniformly sample sets of parameters from the defined parameter ranges.\n",
    "\n",
    "The likelihood is defined by providing both the previously defined prior object and the likelihood functions defined in the previous codeblock. This is done with the following code: `likelihood = Likelihood(prior, likelihood_functions, likelihood_params, chirp_mass)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fda4df-2387-46eb-a4fe-98e6e786d5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variable parameters, same prior as previous papers of Raaijmakers et al.\n",
    "variable_params={'ceft':[polytropes_pp.min_norm, polytropes_pp.max_norm],'gamma1':[1.,4.5],'gamma2':[0.,8.],'gamma3':[0.5,8.],'rho_t1':[1.5,8.3],'rho_t2':[1.5,8.3]}\n",
    "for i in range(number_stars):\n",
    "\tvariable_params.update({'rhoc_' + str(i+1):[14.6, 16]})\n",
    "\n",
    "# Define static parameters, empty dict because all params are variable \n",
    "static_params={}\n",
    "\n",
    "# Define joint prior and joint likelihood\n",
    "prior = Prior(polytropes_pp, variable_params, static_params, chirp_mass)\n",
    "likelihood = Likelihood(prior, likelihood_functions, likelihood_params, chirp_mass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d29c2d2-9483-4355-bf5d-e9c406059a7c",
   "metadata": {},
   "source": [
    "After defining your prior and likelihood function, it is best practice to test your prior and likelihood function. This is done with the short loop in the code block below. This loop will for each iteration first take a sample from the prior, and then compute the corresponding likelihood of said prior sample and print the likelihood as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2dc9f-4b94-4e64-8c9e-a8340e95faed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bounds of prior are\")\n",
    "print(variable_params)\n",
    "print(\"number of parameters is %d\" %len(variable_params))\n",
    "\n",
    "# Perform a test, this will draw 50 random points from the prior and calculate their likelihood\n",
    "print(\"Testing prior and likelihood\")\n",
    "cube = np.random.rand(50, len(variable_params))\n",
    "for i in range(len(cube)):\n",
    "    par = prior.inverse_sample(cube[i])\n",
    "    print(likelihood.call(par))\n",
    "print(\"Testing done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841c4903-4610-4488-91df-b13d1498f1d3",
   "metadata": {},
   "source": [
    "When finished with testing your likelihood and prior you can proceed to the actual inference process. This is done in the code block below. Warning: depending on the performance of your platform, this might be a very slow process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cec10f8-271d-4530-8540-17a6e3406c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we start the sampling with MultiNest\n",
    "start = time.time()\n",
    "result = solve(LogLikelihood=likelihood.call, Prior=prior.inverse_sample, n_live_points=5000, evidence_tolerance=0.1,\n",
    "               n_dims=len(variable_params), sampling_efficiency=0.8, outputfiles_basename='chains/' + run_name, verbose=True)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e72193-9817-4e3d-8b3d-c4af7e9fcc28",
   "metadata": {},
   "source": [
    "Finally, NEoST also includes functionality to perform the first steps of posterior analysis. The first step in this process is to call the `PosteriorAnalysis.compute_auxiliary_data()` function with the code block below. This will generate as output a set of files that can subsequently be used with several additional plotting routines included in NEoST, or you can analyse these files on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1e44a5-11b7-4a7f-9284-f0f9fd243ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute auxiliary data for posterior analysis\n",
    "PosteriorAnalysis.compute_auxiliary_data('chains/' + run_name, polytropes_pp, \n",
    "                                         variable_params, static_params, chirp_mass)klmmm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203267f9-ba8d-4631-be9b-c303f50f14a0",
   "metadata": {},
   "source": [
    "This following plotting routine will create a cornerplot of all the parameters you have included in the `variable_params` dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f6014-bb6b-49a3-b690-885666ed5e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some analysis plots\n",
    "PosteriorAnalysis.cornerplot('chains/' + run_name, variable_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d302d9-f7c9-476b-b9f2-d4f1d3d1b82d",
   "metadata": {},
   "source": [
    "This will plot the data you have used to define the likelihood. So these are the masses and radii of the neutron stars that have been included in the analysis. Note that this will also plot the masses and radii of any gravitational wave events included in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df394e8-d590-4943-9531-e450b9c441e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PosteriorAnalysis.mass_radius_posterior_plot('chains/' + run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f04d37-17fc-443f-9859-320692a07255",
   "metadata": {},
   "source": [
    "This routine will plot the posterior on the mass-radius relationship of neutron stars according to the inference process, the `label_name` parameter will be the label used in the legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9f08e4-c173-430c-8541-0138a3a9ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "PosteriorAnalysis.mass_radius_prior_predictive_plot('chains/' + run_name,variable_params, label_name='+ J0740 + GW170817')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67128cd0-5fd4-4531-859b-551ec68d2c0c",
   "metadata": {},
   "source": [
    "This routine will plot the posterior on the equation of state itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd326f7-f725-403e-9ed5-a28291aa750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PosteriorAnalysis.eos_posterior_plot('chains/' + run_name,variable_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
